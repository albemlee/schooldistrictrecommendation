{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Working Directory\n",
    "import os\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Requirements\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import chardet\n",
    "import zipfile\n",
    "from functools import reduce\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import Imputer, Normalizer, MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "from helper import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtain data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data I used for this project came from the [Common Core Dataset](https://nces.ed.gov/ccd/)  managed by the [National Center of Education Statistics](https://nces.ed.gov/). <br/>\n",
    "\n",
    "In this section we will verify whether the model performs adequately on school districts from the 2004-2005 school year.\n",
    "\n",
    "The datasets needed are: <br/>  \n",
    "- [Universe - District Level - 2004-2005](https://nces.ed.gov/ccd/data/zip/ag041c_dat.zip)\n",
    "- [Universe - School Level - 2004-2005](https://nces.ed.gov/ccd/data/zip/sc041bai_dat.zip): States A-I\n",
    "- [Universe - School Level - 2004-2005](https://nces.ed.gov/ccd/data/zip/sc041bkn_dat.zip): States K-N\n",
    "- [Universe - School Level - 2004-2005](https://nces.ed.gov/ccd/data/zip/sc041bow_dat.zip): States O-W\n",
    "- [Universe - District Level - 2009-2010](https://nces.ed.gov/ccd/data/zip/ag092a_txt.zip)\n",
    "- [Finance - District Level - 2004-2005](https://nces.ed.gov/ccd/data/zip/sdf051c.txt.zip)\n",
    "- [Dropout - District Level - 2004-2005](https://nces.ed.gov/ccd/data/zip/agdr041a_dat.zip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I downloaded the data into the 'data' folder, and they were renamed using a common schema ('filetype_fiscalYYYY.txt.zip'). <br/>\n",
    "\n",
    "Examples:\n",
    "- 'school_universe_fiscal2010.txt.zip'\n",
    "- 'directory_fiscal2015.txt.zip'\n",
    "- 'dropout_fiscal2010.txt.zip'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data into data frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function (load_data) that was used to load the 2009-2010 data into dataframes is stored in the helper file. I used the same function to load the data from 2004-2005.\n",
    "\n",
    "The only features we need (and their corresponding source) are:\n",
    "- total_students (school universe)\n",
    "- total_schools (universe)\n",
    "- teachers_total (universe)\n",
    "- total_revenue (finance)\n",
    "- total_federal_revenue (finance)\n",
    "- total_state_revenue (finance)\n",
    "- total_local_revenue (finance)\n",
    "- total_expenditure (finance)\n",
    "- total_salaries (finance)\n",
    "- white_students (school_universe)\n",
    "- lowest_grade (universe)\n",
    "- highest_grade (universe)\n",
    "- metro_micro (universe)\n",
    "- charter_status (universe)\n",
    "- state_name (finance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read files into dataframes\n",
    "finance_data = load_data('finance', year='2005')\n",
    "universe_data = load_data('universe', year='2005')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finance_data: (16605, 242)\n",
      "universe_data: (18084, 1)\n"
     ]
    }
   ],
   "source": [
    "# Print shapes of data\n",
    "print('finance_data:', finance_data.shape)\n",
    "print('universe_data:', universe_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Universe data is not in delimited format (only 1 column). They are in fixed width formats and will be manually parsed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive = zipfile.ZipFile('data/universe_fiscal2005.txt.zip', 'r')\n",
    "text_file = archive.open('universe_fiscal2005.txt')\n",
    "\n",
    "data_dict = {'LEAID': [],\n",
    "             'total_schools': [],\n",
    "             'teachers_total': [],\n",
    "             'lowest_grade': [],\n",
    "             'highest_grade': [],\n",
    "             'metro_micro': [],\n",
    "             'charter_status': [],\n",
    "             'BOUND04': []}\n",
    "\n",
    "for line in text_file.readlines():\n",
    "    data_dict['LEAID'].append(line[0:7])\n",
    "    data_dict['total_schools'].append(line[289:294])\n",
    "    data_dict['teachers_total'].append(line[294:301])\n",
    "    data_dict['lowest_grade'].append(line[284:286])\n",
    "    data_dict['highest_grade'].append(line[286:288])\n",
    "    data_dict['metro_micro'].append(line[280:281])\n",
    "    data_dict['charter_status'].append(line[288:289])\n",
    "    data_dict['BOUND04'].append(line[283:284])\n",
    "    \n",
    "universe_data = pd.DataFrame.from_dict(data_dict)\n",
    "universe_data['LEAID'] = universe_data['LEAID'].apply(lambda x: x.decode(\"windows-1252\"))\n",
    "universe_data['lowest_grade'] = universe_data['lowest_grade'].apply(lambda x: x.decode(\"windows-1252\"))\n",
    "universe_data['highest_grade'] = universe_data['highest_grade'].apply(lambda x: x.decode(\"windows-1252\"))\n",
    "universe_data['charter_status'] = universe_data['charter_status'].apply(lambda x: x.decode(\"windows-1252\"))\n",
    "universe_data['metro_micro'] = universe_data['metro_micro'].apply(lambda x: x.decode(\"windows-1252\"))\n",
    "universe_data.loc[universe_data['lowest_grade']=='N ', 'lowest_grade'] = float('nan')\n",
    "universe_data.loc[universe_data['highest_grade']=='N ', 'highest_grade'] = float('nan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "universe_data: (18085, 8)\n"
     ]
    }
   ],
   "source": [
    "print('universe_data:', universe_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregate school level universe data to produce district level data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The demographic breakdown of school districts are not available in the district-level universe data. To obtain district-level demographic data, I aggregated the demographic data from the school level.\n",
    "\n",
    "Unlike the 2009-2010 data, the 2004-2005 was in a fixed width format instead of a delimited format. That means that the aggregate_school_data function in the helper file couldn't be applied to the 2004-2005 demographic data, and I had to manually parse the file into a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "demographic_data: (17081, 17)\n"
     ]
    }
   ],
   "source": [
    "archive = zipfile.ZipFile('data/school_universe_fiscal2005.txt.zip', 'r')\n",
    "text_file = archive.open('school_universe_fiscal2005.txt')\n",
    "\n",
    "data_dict = {\n",
    "    'LEAID': [], \n",
    "    'total_students': [],\n",
    "    'american_indian_alaskan_native_students': [], \n",
    "    'american_indian_alaskan_native_male_students': [], \n",
    "    'american_indian_alaskan_native_female_students': [], \n",
    "    'asian_hawaiian_native_pacific_islander_students': [],\n",
    "    'asian_hawaiian_native_pacific_islander_male_students': [],\n",
    "    'asian_hawaiian_native_pacific_islander_female_students': [],\n",
    "    'hispanic_students': [], \n",
    "    'hispanic_male_students': [],\n",
    "    'hispanic_female_students': [], \n",
    "    'black_non_hispanic_students': [], \n",
    "    'black_non_hispanic_male_students': [], \n",
    "    'black_non_hispanic_female_students': [], \n",
    "    'white_students': [], \n",
    "    'white_male_students': [], \n",
    "    'white_female_students': [],\n",
    "}\n",
    "\n",
    "for line in text_file.readlines():\n",
    "    data_dict['LEAID'].append(line[0:7])\n",
    "    data_dict['total_students'].append(line[1358:1362])\n",
    "    data_dict['american_indian_alaskan_native_students'].append(line[1362:1366])\n",
    "    data_dict['american_indian_alaskan_native_male_students'].append(line[1366:1370])\n",
    "    data_dict['american_indian_alaskan_native_female_students'].append(line[1370:1374])\n",
    "    data_dict['asian_hawaiian_native_pacific_islander_students'].append(line[1378:1382])\n",
    "    data_dict['asian_hawaiian_native_pacific_islander_male_students'].append(line[1382:1386])\n",
    "    data_dict['asian_hawaiian_native_pacific_islander_female_students'].append(line[1386:1390])\n",
    "    data_dict['hispanic_students'].append(line[1394:1398])\n",
    "    data_dict['hispanic_male_students'].append(line[1399:1402])\n",
    "    data_dict['hispanic_female_students'].append(line[1403:1406])\n",
    "    data_dict['black_non_hispanic_students'].append(line[1410:1414])\n",
    "    data_dict['black_non_hispanic_male_students'].append(line[1414:1418])\n",
    "    data_dict['black_non_hispanic_female_students'].append(line[1418:1422])\n",
    "    data_dict['white_students'].append(line[1426:1430])\n",
    "    data_dict['white_male_students'].append(line[1430:1434])\n",
    "    data_dict['white_female_students'].append(line[1434:1438])\n",
    "    \n",
    "school_universe_data = pd.DataFrame.from_dict(data_dict)\n",
    "school_universe_data['LEAID'] = school_universe_data['LEAID'].apply(lambda x: x.decode(\"windows-1252\"))\n",
    "for column in school_universe_data.columns:\n",
    "    if column != 'LEAID':\n",
    "        school_universe_data[column] = pd.to_numeric(school_universe_data[column])\n",
    "        \n",
    "demographic_data = school_universe_data.groupby('LEAID').sum(skipna=True, min_count=1).reset_index()\n",
    "print('demographic_data:', demographic_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because these steps take a long time to complete, I saved the aggregated dataset into a csv file. It is saved in the 'output' folder as 'demographic_data.csv.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save aggregated demographic data into outputs folder for later use\n",
    "demographic_data.to_csv(\"output/demographic_data_05.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge data frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merged_data: (18141, 265)\n"
     ]
    }
   ],
   "source": [
    "# Execute merge_data function\n",
    "merged_data = merge_data(finance_data, universe_data, demographic_data)\n",
    "print('merged_data:', merged_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove flag columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to documentation, columns that begin with 'FL_' are used to flag data in other columns, and they would not be useful for the analysis. I created a function to remove columns that begin with 'FL_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merged_data: (18141, 158)\n"
     ]
    }
   ],
   "source": [
    "merged_data = remove_flag_columns(merged_data)\n",
    "print('merged_data:', merged_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identify NA values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to documentation, there are multiple types of flagged values.\n",
    "- -1: missing data\n",
    "- -2: non-applicable data\n",
    "- -9, -3, -4: low quality data\n",
    "\n",
    "I decided to change missing and low quality values to na and change non-applicable data to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing values before: 224028\n",
      "missing values after: 224272\n"
     ]
    }
   ],
   "source": [
    "print('missing values before:', pd.isnull(merged_data).sum().sum())\n",
    "merged_data = encode_missing_values(merged_data)\n",
    "print('missing values after:', pd.isnull(merged_data).sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create column to represent whether school district is still operational in 5 years"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective is to predict whether school district will still be operational in 5 years.\n",
    "\n",
    "I created a column within the data frame to represent whether the school district is still operational in 5 years. To do that, I found school districts in the 2009-2010 universe file that were not found in the 2014-2015 membership file and marked them as being no longer operational. In addition, there are columns representing whether the school district is currently operational ('BOUND09 for 2009-2010 and 'SY_STATUS' for 2014-2015), and I marked school districts that are currently not operational as not being operational in five years as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_data = load_data('universe', year='2010')\n",
    "\n",
    "def condition1_generate(x):\n",
    "    \"\"\"\n",
    "    Return boolean of whether school district exists in 5 years\n",
    "\n",
    "    param string x: LEAID of school district to check\n",
    "    \"\"\"\n",
    "    condition1 = x in directory_data['LEAID'].values\n",
    "    if condition1:\n",
    "        condition1 = directory_data.loc[directory_data['LEAID']==x, 'BOUND09'].values != '2'\n",
    "    return condition1\n",
    "\n",
    "condition1 = merged_data['LEAID'].apply(condition1_generate)\n",
    "condition2 = merged_data['BOUND04'].apply(lambda x: x != '2')\n",
    "\n",
    "merged_data['exist_five_years'] = condition1 & condition2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data.rename({'TOTALREV': 'total_revenue',\n",
    "                    'TFEDREV': 'total_federal_revenue',\n",
    "                    'TSTREV': 'total_state_revenue',\n",
    "                    'TLOCREV': 'total_local_revenue',\n",
    "                    'TOTALEXP': 'total_expenditure',\n",
    "                    'Z32': 'total_salaries',\n",
    "                    'STNAME': 'state_name'}, \n",
    "                   axis='columns',\n",
    "                   inplace=True)\n",
    "\n",
    "merged_data['state_name'] = merged_data['state_name'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_features = ['total_students',\n",
    "                 'total_schools',\n",
    "                 'teachers_total',\n",
    "                 'total_revenue',\n",
    "                 'total_federal_revenue',\n",
    "                 'total_state_revenue',\n",
    "                 'total_local_revenue',\n",
    "                 'total_expenditure',\n",
    "                 'total_salaries',\n",
    "                 'white_students',\n",
    "                 'lowest_grade',\n",
    "                 'highest_grade',\n",
    "                 'metro_micro',\n",
    "                 'charter_status',\n",
    "                 'state_name',\n",
    "                 'LEAID',\n",
    "                 'NAME',\n",
    "                 'exist_five_years']\n",
    "\n",
    "wrangled_data = merged_data[keep_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dataframe to csv\n",
    "wrangled_data.to_csv('output/wrangled_data_ii_2005.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train, y_train, X_dev, y_dev, X_test, y_test = prep_columns_cluster(wrangled_data)\n",
    "\n",
    "X = pd.concat([X_train, X_dev, X_test])\n",
    "y = pd.concat([y_train, y_dev, y_test])\n",
    "\n",
    "five_cluster_pipeline = joblib.load(open('output/pipelines/cluster_pipeline.sav', 'rb'))\n",
    "\n",
    "clusters = five_cluster_pipeline.predict(X)\n",
    "labels = y.apply(lambda x: x==False).values.ravel()\n",
    "\n",
    "cluster_frame = pd.DataFrame({'LEAID': wrangled_data.loc[X.index, 'LEAID'], \n",
    "                              'NAME': wrangled_data.loc[X.index, 'NAME'], \n",
    "                              'cluster': clusters, \n",
    "                              'label': labels})\n",
    "\n",
    "cluster_frame.to_csv('output/cluster_results_2005.csv', index=False)\n",
    "\n",
    "def percentage_under(values):\n",
    "    return 100 * sum(values)/len(values)\n",
    "cluster_frame[['cluster', 'label']].groupby('cluster').agg(percentage_under).plot.barh()\n",
    "\n",
    "plt.xlim(0, 100)\n",
    "plt.savefig('output/plots/clusters_2005.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_frame.to_csv('output/cluster_results_2005.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
